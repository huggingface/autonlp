task: lm_training
base_model: meta-llama/Meta-Llama-3-8B-Instruct
project_name: llama3-8b-orpo
log: tensorboard
backend: local-cli

data:
  # path can also be a local folder. 
  # if a local folder is provided, the training and validation files
  # must be named "train.csv" and "valid.csv" respectively or
  # "train.jsonl" and "valid.jsonl" respectively.
  # validation split will be ignored for llm training.
  path: argilla/distilabel-capybara-dpo-7k-binarized
  train_split: train
  valid_split: valid
  chat_template: chatml
  column_mapping:
    text_column: chosen
    rejected_text_column: rejected

params:
  trainer: orpo
  block_size: 1024
  model_max_length: 8192
  max_prompt_length: 512
  epochs: 3
  batch_size: 2
  lr: 3e-5
  peft: true
  quantization: int4
  target_modules: all-linear
  padding: right
  optimizer: adamw_torch
  scheduler: linear
  gradient_accumulation: 4

hub:
  username: ${HF_USERNAME}
  token: ${HF_TOKEN}
  push_to_hub: true